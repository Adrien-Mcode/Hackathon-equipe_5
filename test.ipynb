{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "classified-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "labeled-transport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://nexusm-repo-mob.apps.eul.sncf.fr/repository/pypi-public/simple"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting scikit-learn\n",
      "  Downloading https://nexusm-repo-mob.apps.eul.sncf.fr/repository/pypi-public/packages/packages/3c/d3/63700971e89bc5024d4356310229f5cdc93927c8c8bf95c53bb7b5e4a62e/scikit_learn-0.24.1-cp36-cp36m-win_amd64.whl (6.8MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\9605647w\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages (from scikit-learn) (1.19.5)\n",
      "Collecting joblib>=0.11 (from scikit-learn)\n",
      "  Downloading https://nexusm-repo-mob.apps.eul.sncf.fr/repository/pypi-public/packages/packages/55/85/70c6602b078bd9e6f3da4f467047e906525c355a4dacd4f71b97a35d9897/joblib-1.0.1-py3-none-any.whl (303kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading https://nexusm-repo-mob.apps.eul.sncf.fr/repository/pypi-public/packages/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Collecting scipy>=0.19.1 (from scikit-learn)\n",
      "  Using cached https://nexusm-repo-mob.apps.eul.sncf.fr/repository/pypi-public/packages/packages/f3/9f/80522344838ae24cac9e945240436269cbb92349f7f1f4c9dfc10cb6bad5/scipy-1.5.4-cp36-cp36m-win_amd64.whl\n",
      "Installing collected packages: joblib, threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.1 scipy-1.5.4 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "soviet-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\", nrows=10, parse_dates=[\"date\", \"items_first_enabled_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sixth-prescription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['date', 'store_id', 'parent_chain_id', 'store_country',\n",
       "       'country_iso_code', 'region_id', 'store_region', 'store_segment',\n",
       "       'store_activity_name', 'items_first_enabled_date',\n",
       "       'store_first_saving_date', 'store_last_saving_date', 'item_id',\n",
       "       'item_name', 'before_price', 'currency_code', 'pickup_start',\n",
       "       'pickup_end', 'total_supply', 'declared_supply',\n",
       "       'manual_added_supply', 'manual_removed_supply', 'meals_saved',\n",
       "       'consumer_cancellation', 'store_cancellation', 'item_price',\n",
       "       'meals_refunded', 'rating_count', 'sum_rating_overall',\n",
       "       'item_view', 'no_unique_consumers', 'is_enabled', 'Département',\n",
       "       'target'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "green-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop([\"target\"], axis=1), df[\"target\"], test_size=1 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "focused-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.0\n",
       "7    0.0\n",
       "8    0.0\n",
       "5    0.0\n",
       "0    0.0\n",
       "2    0.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "recreational-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "saved-failure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy_score'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adverse-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "def write_yaml(d: dict, filename: str):\n",
    "    with open(filename, 'w', encoding='utf8') as yaml_file:\n",
    "        yaml.dump(d, yaml_file, default_flow_style=False)\n",
    "\n",
    "for model_type in [\"rfc\", \"logit\", \"lightgbm\"]:\n",
    "    for nrows_train in [500, 1000, 10000, 100000, 500000]:\n",
    "        for kind_imputer in [\"iterative\", \"simple\"]:\n",
    "            for only_quantitative in [True, False]:\n",
    "                if not((model_type == \"logit\") & (nrows_train > 1000)):\n",
    "                    dico = {\"nrows_train\": nrows_train,\n",
    "                            \"nrows_test\": 100000,\n",
    "                            \"model_name\": f\"{model_type}_{nrows_train}_{kind_imputer}_{only_quantitative}\",\n",
    "                            \"get_new\": False,\n",
    "                            \"sample_name\": \"dummy_sample\",\n",
    "                            \"only_quantitative\": only_quantitative,\n",
    "                            \"target_encoding\": not(only_quantitative),\n",
    "                            \"model_type\": model_type,\n",
    "                            \"kind_imputer\": kind_imputer,\n",
    "                            \"quantitative_cols\": ['total_supply', 'declared_supply', 'manual_added_supply', \n",
    "                                                 'manual_removed_supply', 'meals_saved', 'consumer_cancellation',\n",
    "                                                 'store_cancellation', 'item_price', 'meals_refunded', 'rating_count',\n",
    "                                                 'sum_rating_overall'],\n",
    "                            \"qualitative_cols\": ['date', \"is_enabled\",\n",
    "                                                 \"items_first_enabled_date\", \"store_first_saving_date\", \n",
    "                                                 \"store_last_saving_date\", \"pickup_start\", \"pickup_end\"]\n",
    "                           }\n",
    "                    write_yaml(dico, f\"config/{model_type}_{nrows_train}_{kind_imputer}_{only_quantitative}.yml\")\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "intelligent-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import category_encoders as ce\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "'region_id','store_segment',\n",
    "                                                   'store_activity_name', \n",
    "                                                   'item_name',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "downtown-tennessee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://nexusm-repo-mob.apps.eul.sncf.fr/repository/pypi-public/simple"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting category_encoders\n",
      "  Downloading https://nexusm-repo-mob.apps.eul.sncf.fr/repository/pypi-public/packages/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
      "Requirement already satisfied: pandas>=0.21.1 in c:\\users\\9605647w\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages (from category_encoders) (1.1.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\9605647w\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages (from category_encoders) (1.5.4)\n",
      "Collecting statsmodels>=0.9.0 (from category_encoders)\n",
      "  Downloading https://nexusm-repo-mob.apps.eul.sncf.fr/repository/pypi-public/packages/packages/09/27/69194eb3a1b6ea6653e1d9cf745b38a2e13b851abc6bfaa9c05212b71a09/statsmodels-0.12.2-cp36-none-win_amd64.whl (9.3MB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\9605647w\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages (from category_encoders) (1.19.5)\n",
      "Collecting patsy>=0.5.1 (from category_encoders)\n",
      "  Downloading https://nexusm-repo-mob.apps.eul.sncf.fr/repository/pypi-public/packages/packages/ea/0c/5f61f1a3d4385d6bf83b83ea495068857ff8dfb89e74824c6e9eb63286d8/patsy-0.5.1-py2.py3-none-any.whl (231kB)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\9605647w\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages (from category_encoders) (0.24.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\9605647w\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\9605647w\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\9605647w\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\9605647w\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\9605647w\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
      "Installing collected packages: patsy, statsmodels, category-encoders\n",
      "Successfully installed category-encoders-2.2.2 patsy-0.5.1 statsmodels-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "direct-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Pipeline(steps=[('te', ce.TargetEncoder(cols=['region_id']))])\n",
    "c = ColumnTransformer([('imp', enc, ['region_id'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fatty-transparency",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\9605647w\\.pyenv\\pyenv-win\\versions\\3.6.8\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('imp',\n",
       "                                 Pipeline(steps=[('te',\n",
       "                                                  TargetEncoder(cols=['region_id']))]),\n",
       "                                 ['region_id'])])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.fit(df.drop([\"target\"], axis=1), df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "mathematical-processing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\9605647W\\\\OneDrive - SNCF\\\\Bureau\\\\repo_prog\\\\Hackathon-equipe_5'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "friendly-cutting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rfc', '500', 'simple', 'True', 'dummy', 'sample']\n",
      "['lightgbm', '100000', 'iterative', 'False', 'dummy', 'sample']\n",
      "['lightgbm', '100000', 'iterative', 'True', 'dummy', 'sample']\n",
      "['lightgbm', '100000', 'simple', 'False', 'dummy', 'sample']\n",
      "['lightgbm', '100000', 'simple', 'True', 'dummy', 'sample']\n",
      "['lightgbm', '10000', 'iterative', 'False', 'dummy', 'sample']\n",
      "['lightgbm', '10000', 'iterative', 'True', 'dummy', 'sample']\n",
      "['lightgbm', '10000', 'simple', 'False', 'dummy', 'sample']\n",
      "['lightgbm', '10000', 'simple', 'True', 'dummy', 'sample']\n",
      "['lightgbm', '1000', 'iterative', 'False', 'dummy', 'sample']\n",
      "['lightgbm', '1000', 'iterative', 'True', 'dummy', 'sample']\n",
      "['lightgbm', '1000', 'simple', 'False', 'dummy', 'sample']\n",
      "['lightgbm', '1000', 'simple', 'True', 'dummy', 'sample']\n",
      "['lightgbm', '500000', 'iterative', 'False', 'dummy', 'sample']\n",
      "['lightgbm', '500000', 'iterative', 'True', 'dummy', 'sample']\n",
      "['lightgbm', '500000', 'simple', 'False', 'dummy', 'sample']\n",
      "['lightgbm', '500000', 'simple', 'True', 'dummy', 'sample']\n",
      "['lightgbm', '500', 'iterative', 'False', 'dummy', 'sample']\n",
      "['lightgbm', '500', 'iterative', 'True', 'dummy', 'sample']\n",
      "['lightgbm', '500', 'simple', 'False', 'dummy', 'sample']\n",
      "['lightgbm', '500', 'simple', 'True', 'dummy', 'sample']\n",
      "['logit', '1000', 'iterative', 'False', 'dummy', 'sample']\n",
      "['logit', '1000', 'iterative', 'True', 'dummy', 'sample']\n",
      "['logit', '1000', 'simple', 'False', 'dummy', 'sample']\n",
      "['logit', '1000', 'simple', 'True', 'dummy', 'sample']\n",
      "['logit', '500', 'iterative', 'False', 'dummy', 'sample']\n",
      "['logit', '500', 'iterative', 'True', 'dummy', 'sample']\n",
      "['logit', '500', 'simple', 'False', 'dummy', 'sample']\n",
      "['logit', '500', 'simple', 'True', 'dummy', 'sample']\n",
      "['rfc', '100000', 'iterative', 'False', 'dummy', 'sample']\n",
      "['rfc', '100000', 'iterative', 'True', 'dummy', 'sample']\n",
      "['rfc', '100000', 'simple', 'False', 'dummy', 'sample']\n",
      "['rfc', '100000', 'simple', 'True', 'dummy', 'sample']\n",
      "['rfc', '10000', 'iterative', 'False', 'dummy', 'sample']\n",
      "['rfc', '10000', 'iterative', 'True', 'dummy', 'sample']\n",
      "['rfc', '10000', 'simple', 'False', 'dummy', 'sample']\n",
      "['rfc', '10000', 'simple', 'True', 'dummy', 'sample']\n",
      "['rfc', '1000', 'iterative', 'False', 'dummy', 'sample']\n",
      "['rfc', '1000', 'iterative', 'True', 'dummy', 'sample']\n",
      "['rfc', '1000', 'simple', 'False', 'dummy', 'sample']\n",
      "['rfc', '1000', 'simple', 'True', 'dummy', 'sample']\n",
      "['rfc', '500000', 'iterative', 'False', 'dummy', 'sample']\n",
      "['rfc', '500000', 'iterative', 'True', 'dummy', 'sample']\n",
      "['rfc', '500000', 'simple', 'False', 'dummy', 'sample']\n",
      "['rfc', '500000', 'simple', 'True', 'dummy', 'sample']\n",
      "['rfc', '500', 'iterative', 'False', 'dummy', 'sample']\n",
      "['rfc', '500', 'iterative', 'True', 'dummy', 'sample']\n",
      "['rfc', '500', 'simple', 'False', 'dummy', 'sample']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"figure/\")\n",
    "conf_matrix_list = []\n",
    "scores_list = []\n",
    "feature_importances_list = []\n",
    "for elem in os.listdir(\"figure/\"):\n",
    "    print(list_name)\n",
    "    list_name = elem.split(\"_\")\n",
    "    model = list_name[0]\n",
    "    sample_size = list_name[1]\n",
    "    imputer = list_name[2]\n",
    "    only_quantitative = list_name[3]\n",
    "    \n",
    "    'test_feature_importance.csv'\n",
    "    'test_scores.csv'\n",
    "    'train_confusion_matrix.csv'\n",
    "    'test_confusion_matrix.csv'\n",
    "    'train_feature_importance.csv'\n",
    "    'train_scores.csv'\n",
    "    conf_matrix = pd.read_csv(\"figure/\" + elem + \"/test_confusion_matrix.csv\").set_index(\"Unnamed: 0\").stack().to_frame().T\n",
    "    conf_matrix[\"type\"] = \"test\"\n",
    "    conf_matrix[\"model\"] = model\n",
    "    conf_matrix[\"sample_size\"] = sample_size\n",
    "    conf_matrix[\"only_quantitative\"] = only_quantitative\n",
    "    conf_matrix[\"inputer\"] = imputer\n",
    "    conf_matrix_list.append(conf_matrix)\n",
    "    \n",
    "    conf_matrix = pd.read_csv(\"figure/\" + elem + \"/train_confusion_matrix.csv\").set_index(\"Unnamed: 0\").stack().to_frame().T\n",
    "    conf_matrix[\"type\"] = \"train\"\n",
    "    conf_matrix[\"model\"] = model\n",
    "    conf_matrix[\"sample_size\"] = sample_size\n",
    "    conf_matrix[\"only_quantitative\"] = only_quantitative\n",
    "    conf_matrix[\"inputer\"] = imputer\n",
    "    conf_matrix_list.append(conf_matrix)\n",
    "    \n",
    "    scores = pd.read_csv(\"figure/\" + elem + \"/test_scores.csv\").set_index(\"Unnamed: 0\").T\n",
    "    scores[\"type\"] = \"test\"\n",
    "    scores[\"model\"] = model\n",
    "    scores[\"sample_size\"] = sample_size\n",
    "    scores[\"only_quantitative\"] = only_quantitative\n",
    "    scores[\"inputer\"] = imputer\n",
    "    scores_list.append(scores)\n",
    "                         \n",
    "    scores = pd.read_csv(\"figure/\" + elem + \"/train_scores.csv\").set_index(\"Unnamed: 0\").T\n",
    "    scores[\"type\"] = \"train\"\n",
    "    scores[\"model\"] = model\n",
    "    scores[\"sample_size\"] = sample_size\n",
    "    scores[\"only_quantitative\"] = only_quantitative\n",
    "    scores[\"inputer\"] = imputer\n",
    "    scores_list.append(scores)\n",
    "    \n",
    "    feature_importances = pd.read_csv(\"figure/\" + elem + \"/test_feature_importance.csv\").set_index(\"Unnamed: 0\").sort_index().T\n",
    "    feature_importances[\"type\"] = \"test\"\n",
    "    feature_importances[\"model\"] = model\n",
    "    feature_importances[\"sample_size\"] = sample_size\n",
    "    feature_importances[\"only_quantitative\"] = only_quantitative\n",
    "    feature_importances[\"inputer\"] = imputer\n",
    "    feature_importances_list.append(feature_importances)\n",
    "               \n",
    "    feature_importances = pd.read_csv(\"figure/\" + elem + \"/train_feature_importance.csv\").set_index(\"Unnamed: 0\").sort_index().T\n",
    "    feature_importances[\"type\"] = \"train\"\n",
    "    feature_importances[\"model\"] = model\n",
    "    feature_importances[\"sample_size\"] = sample_size\n",
    "    feature_importances[\"only_quantitative\"] = only_quantitative\n",
    "    feature_importances[\"inputer\"] = imputer\n",
    "    feature_importances_list.append(feature_importances)\n",
    "    \n",
    "feature_importance_fin = pd.concat(feature_importances_list)\n",
    "feature_importance_fin.to_csv(\"feature_importance_fin.csv\")\n",
    "scores_fin = pd.concat(scores_list)\n",
    "scores_fin.to_csv(\"scores_fin.csv\")\n",
    "conf_matrix_fin = pd.concat(conf_matrix_list)\n",
    "scores_fin.to_csv(\"conf_matrix_fin.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "transsexual-ireland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>consumer_cancellation</th>\n",
       "      <th>date</th>\n",
       "      <th>declared_supply</th>\n",
       "      <th>is_enabled</th>\n",
       "      <th>item_price</th>\n",
       "      <th>items_first_enabled_date</th>\n",
       "      <th>manual_added_supply</th>\n",
       "      <th>manual_removed_supply</th>\n",
       "      <th>meals_refunded</th>\n",
       "      <th>meals_saved</th>\n",
       "      <th>pickup_end</th>\n",
       "      <th>pickup_start</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>store_cancellation</th>\n",
       "      <th>store_first_saving_date</th>\n",
       "      <th>store_last_saving_date</th>\n",
       "      <th>sum_rating_overall</th>\n",
       "      <th>total_supply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature_importance</th>\n",
       "      <td>-0.066921</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>-0.047178</td>\n",
       "      <td>-0.063051</td>\n",
       "      <td>-0.063006</td>\n",
       "      <td>-0.056526</td>\n",
       "      <td>-0.066529</td>\n",
       "      <td>-0.066923</td>\n",
       "      <td>-0.066948</td>\n",
       "      <td>-0.066948</td>\n",
       "      <td>0.033222</td>\n",
       "      <td>0.029225</td>\n",
       "      <td>-0.066948</td>\n",
       "      <td>-0.06665</td>\n",
       "      <td>-0.054363</td>\n",
       "      <td>0.018905</td>\n",
       "      <td>-0.066948</td>\n",
       "      <td>0.109838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0          consumer_cancellation      date  declared_supply  \\\n",
       "feature_importance              -0.066921  0.014288        -0.047178   \n",
       "\n",
       "Unnamed: 0          is_enabled  item_price  items_first_enabled_date  \\\n",
       "feature_importance   -0.063051   -0.063006                 -0.056526   \n",
       "\n",
       "Unnamed: 0          manual_added_supply  manual_removed_supply  \\\n",
       "feature_importance            -0.066529              -0.066923   \n",
       "\n",
       "Unnamed: 0          meals_refunded  meals_saved  pickup_end  pickup_start  \\\n",
       "feature_importance       -0.066948    -0.066948    0.033222      0.029225   \n",
       "\n",
       "Unnamed: 0          rating_count  store_cancellation  store_first_saving_date  \\\n",
       "feature_importance     -0.066948            -0.06665                -0.054363   \n",
       "\n",
       "Unnamed: 0          store_last_saving_date  sum_rating_overall  total_supply  \n",
       "feature_importance                0.018905           -0.066948      0.109838  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('figure/lightgbm_100000_iterative_False_dummy_sample/test_feature_importance.csv').set_index(\"Unnamed: 0\").sort_index().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "upset-warrior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.yml',\n",
       " 'test_confusion_matrix.csv',\n",
       " 'test_feature_importance.csv',\n",
       " 'test_scores.csv',\n",
       " 'train_confusion_matrix.csv',\n",
       " 'train_feature_importance.csv',\n",
       " 'train_scores.csv']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table(index = 'Tech', columns = ['Year', 'Scenario'], values = 'Sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "gorgeous-concrete",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>consumer_cancellation</th>\n",
       "      <th>date</th>\n",
       "      <th>declared_supply</th>\n",
       "      <th>is_enabled</th>\n",
       "      <th>item_price</th>\n",
       "      <th>items_first_enabled_date</th>\n",
       "      <th>manual_added_supply</th>\n",
       "      <th>manual_removed_supply</th>\n",
       "      <th>meals_refunded</th>\n",
       "      <th>...</th>\n",
       "      <th>store_cancellation</th>\n",
       "      <th>store_first_saving_date</th>\n",
       "      <th>store_last_saving_date</th>\n",
       "      <th>sum_rating_overall</th>\n",
       "      <th>total_supply</th>\n",
       "      <th>type</th>\n",
       "      <th>model</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>only_quantitative</th>\n",
       "      <th>inputer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_importance</td>\n",
       "      <td>-0.066921</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>-0.047178</td>\n",
       "      <td>-0.063051</td>\n",
       "      <td>-0.063006</td>\n",
       "      <td>-0.056526</td>\n",
       "      <td>-0.066529</td>\n",
       "      <td>-0.066923</td>\n",
       "      <td>-0.066948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066650</td>\n",
       "      <td>-0.054363</td>\n",
       "      <td>0.018905</td>\n",
       "      <td>-0.066948</td>\n",
       "      <td>0.109838</td>\n",
       "      <td>test</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>100000</td>\n",
       "      <td>False</td>\n",
       "      <td>iterative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature_importance</td>\n",
       "      <td>-0.081322</td>\n",
       "      <td>-0.000865</td>\n",
       "      <td>-0.063349</td>\n",
       "      <td>-0.076579</td>\n",
       "      <td>-0.075689</td>\n",
       "      <td>-0.067189</td>\n",
       "      <td>-0.080289</td>\n",
       "      <td>-0.081368</td>\n",
       "      <td>-0.081389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081251</td>\n",
       "      <td>-0.066234</td>\n",
       "      <td>-0.002541</td>\n",
       "      <td>-0.081389</td>\n",
       "      <td>0.110584</td>\n",
       "      <td>train</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>100000</td>\n",
       "      <td>False</td>\n",
       "      <td>iterative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature_importance</td>\n",
       "      <td>-0.127379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.126491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.073619</td>\n",
       "      <td>-0.120693</td>\n",
       "      <td>-0.127367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.127367</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>test</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>100000</td>\n",
       "      <td>True</td>\n",
       "      <td>iterative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_importance</td>\n",
       "      <td>-0.127258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.126161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.071868</td>\n",
       "      <td>-0.120217</td>\n",
       "      <td>-0.127292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.127292</td>\n",
       "      <td>0.018784</td>\n",
       "      <td>train</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>100000</td>\n",
       "      <td>True</td>\n",
       "      <td>iterative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_importance</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>-0.044718</td>\n",
       "      <td>-0.062544</td>\n",
       "      <td>-0.063464</td>\n",
       "      <td>-0.056702</td>\n",
       "      <td>-0.065990</td>\n",
       "      <td>-0.066958</td>\n",
       "      <td>-0.066948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067010</td>\n",
       "      <td>-0.054680</td>\n",
       "      <td>0.019037</td>\n",
       "      <td>-0.066948</td>\n",
       "      <td>0.111851</td>\n",
       "      <td>test</td>\n",
       "      <td>lightgbm</td>\n",
       "      <td>100000</td>\n",
       "      <td>False</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>feature_importance</td>\n",
       "      <td>-0.121433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.124975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.073972</td>\n",
       "      <td>-0.116326</td>\n",
       "      <td>-0.127088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.127073</td>\n",
       "      <td>0.014428</td>\n",
       "      <td>train</td>\n",
       "      <td>rfc</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>iterative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>feature_importance</td>\n",
       "      <td>0.059111</td>\n",
       "      <td>0.177797</td>\n",
       "      <td>0.158138</td>\n",
       "      <td>0.082828</td>\n",
       "      <td>0.072134</td>\n",
       "      <td>0.096985</td>\n",
       "      <td>0.063062</td>\n",
       "      <td>0.059399</td>\n",
       "      <td>0.058998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059285</td>\n",
       "      <td>0.094684</td>\n",
       "      <td>0.170325</td>\n",
       "      <td>0.059442</td>\n",
       "      <td>0.195919</td>\n",
       "      <td>test</td>\n",
       "      <td>rfc</td>\n",
       "      <td>500</td>\n",
       "      <td>False</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>feature_importance</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>0.210209</td>\n",
       "      <td>0.146118</td>\n",
       "      <td>0.027413</td>\n",
       "      <td>0.072788</td>\n",
       "      <td>0.130366</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>-0.000810</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000719</td>\n",
       "      <td>0.127773</td>\n",
       "      <td>0.218703</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>0.203339</td>\n",
       "      <td>train</td>\n",
       "      <td>rfc</td>\n",
       "      <td>500</td>\n",
       "      <td>False</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>feature_importance</td>\n",
       "      <td>-0.120953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.125625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.075664</td>\n",
       "      <td>-0.116037</td>\n",
       "      <td>-0.127214</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.127224</td>\n",
       "      <td>0.017337</td>\n",
       "      <td>test</td>\n",
       "      <td>rfc</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>feature_importance</td>\n",
       "      <td>-0.122669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.124428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.068503</td>\n",
       "      <td>-0.116685</td>\n",
       "      <td>-0.127092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.127114</td>\n",
       "      <td>0.017162</td>\n",
       "      <td>train</td>\n",
       "      <td>rfc</td>\n",
       "      <td>500</td>\n",
       "      <td>True</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0  consumer_cancellation      date  declared_supply  \\\n",
       "0   feature_importance              -0.066921  0.014288        -0.047178   \n",
       "1   feature_importance              -0.081322 -0.000865        -0.063349   \n",
       "2   feature_importance              -0.127379       NaN        -0.004689   \n",
       "3   feature_importance              -0.127258       NaN        -0.001979   \n",
       "4   feature_importance              -0.066937  0.013109        -0.044718   \n",
       "..                 ...                    ...       ...              ...   \n",
       "91  feature_importance              -0.121433       NaN        -0.007443   \n",
       "92  feature_importance               0.059111  0.177797         0.158138   \n",
       "93  feature_importance              -0.000974  0.210209         0.146118   \n",
       "94  feature_importance              -0.120953       NaN        -0.004066   \n",
       "95  feature_importance              -0.122669       NaN        -0.006499   \n",
       "\n",
       "    is_enabled  item_price  items_first_enabled_date  manual_added_supply  \\\n",
       "0    -0.063051   -0.063006                 -0.056526            -0.066529   \n",
       "1    -0.076579   -0.075689                 -0.067189            -0.080289   \n",
       "2          NaN   -0.126491                       NaN            -0.073619   \n",
       "3          NaN   -0.126161                       NaN            -0.071868   \n",
       "4    -0.062544   -0.063464                 -0.056702            -0.065990   \n",
       "..         ...         ...                       ...                  ...   \n",
       "91         NaN   -0.124975                       NaN            -0.073972   \n",
       "92    0.082828    0.072134                  0.096985             0.063062   \n",
       "93    0.027413    0.072788                  0.130366             0.002556   \n",
       "94         NaN   -0.125625                       NaN            -0.075664   \n",
       "95         NaN   -0.124428                       NaN            -0.068503   \n",
       "\n",
       "    manual_removed_supply  meals_refunded  ...  store_cancellation  \\\n",
       "0               -0.066923       -0.066948  ...           -0.066650   \n",
       "1               -0.081368       -0.081389  ...           -0.081251   \n",
       "2               -0.120693       -0.127367  ...           -0.124596   \n",
       "3               -0.120217       -0.127292  ...           -0.123751   \n",
       "4               -0.066958       -0.066948  ...           -0.067010   \n",
       "..                    ...             ...  ...                 ...   \n",
       "91              -0.116326       -0.127088  ...           -0.119443   \n",
       "92               0.059399        0.058998  ...            0.059285   \n",
       "93              -0.000810       -0.001003  ...           -0.000719   \n",
       "94              -0.116037       -0.127214  ...           -0.119309   \n",
       "95              -0.116685       -0.127092  ...           -0.119546   \n",
       "\n",
       "    store_first_saving_date  store_last_saving_date  sum_rating_overall  \\\n",
       "0                 -0.054363                0.018905           -0.066948   \n",
       "1                 -0.066234               -0.002541           -0.081389   \n",
       "2                       NaN                     NaN           -0.127367   \n",
       "3                       NaN                     NaN           -0.127292   \n",
       "4                 -0.054680                0.019037           -0.066948   \n",
       "..                      ...                     ...                 ...   \n",
       "91                      NaN                     NaN           -0.127073   \n",
       "92                 0.094684                0.170325            0.059442   \n",
       "93                 0.127773                0.218703           -0.001003   \n",
       "94                      NaN                     NaN           -0.127224   \n",
       "95                      NaN                     NaN           -0.127114   \n",
       "\n",
       "    total_supply   type     model  sample_size  only_quantitative    inputer  \n",
       "0       0.109838   test  lightgbm       100000              False  iterative  \n",
       "1       0.110584  train  lightgbm       100000              False  iterative  \n",
       "2       0.014060   test  lightgbm       100000               True  iterative  \n",
       "3       0.018784  train  lightgbm       100000               True  iterative  \n",
       "4       0.111851   test  lightgbm       100000              False     simple  \n",
       "..           ...    ...       ...          ...                ...        ...  \n",
       "91      0.014428  train       rfc          500               True  iterative  \n",
       "92      0.195919   test       rfc          500              False     simple  \n",
       "93      0.203339  train       rfc          500              False     simple  \n",
       "94      0.017337   test       rfc          500               True     simple  \n",
       "95      0.017162  train       rfc          500               True     simple  \n",
       "\n",
       "[96 rows x 24 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"feature_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-fever",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
